---
cover: /articles/article-2/cover.png
date: 2024-05-08
description: Advertisement Photography with Stable Diffusion.
layout: article
---
# ComfyUI: Advertisement Photography with Stable Diffusion

**Generating photorealistic results with Stable Diffusion while keeping an object of interest unchanged.**

![Workflow Screenshot](/articles/article-2/cover.png)
![Workflow Screenshot](/articles/article-2/workflow1.png)

**👉🏻 Download the workflow - [workflow.json](https://github.com/martintmv-git/comfyui-experiments/blob/main/Photography%20Mask%20Studio/workflow.json).**

## Table of Contents
1. [Models and Nodes Setup](#models-and-nodes-setup)
   - [Models](#models)
   - [Nodes](#nodes)
2. [Workflow Overview](#workflow-overview)
3. [Workflow Results](#workflow-results)


## Models and Nodes Setup

### Models

- [RealVisXL V4.0](https://civitai.com/models/139562/realvisxl-v40)
- [SDXL LoRA](https://huggingface.co/ByteDance/SDXL-Lightning/tree/main)
- [Depth Anything](https://huggingface.co/LiheYoung/depth_anything_vitl14)
- [ControlNet SDXL](https://huggingface.co/lllyasviel/sd_control_collection/tree/main)


### Nodes

- **ComfyUI Manager**: A tool for managing nodes and models within ComfyUI. [ComfyUI Manager GitHub repository](https://github.com/ltdrdata/ComfyUI-Manager)

> **👉🏻 You can install all missing nodes in a workflow, or install custom nodes with ease from the Manager Menu. Restart your ComfyUI after installation.**
![ComfyUI Manager](/articles/article-1/comfyui-manager.png)
Of course you can install nodes manually with `git` and the `terminal`, but the Manager is a great tool to have.

## Workflow Overview

### 1. Initial Setup and Image Loading
- **Load Image Node**: This is the starting point of the workflow, where an initial image is loaded into the system. This could be any image you intend to use as a base. 

> It's recommended to use high-quality and square images for better results in the final output, as SDXL models work with square images.

- **Load Checkpoint Node**: Loads various model checkpoints, providing capabilities like CLIP, VAE, and others for text and image encoding or decoding. This node ensures that the models necessary for processing and synthesis are ready and optimized for the tasks ahead.

- **Load LoRA Node**: Specifically loads the Lora model, equipped for detailed control and manipulation within the image synthesis process, using configurations like `sdxl_lightning_4step_lora.safetensors`.

![Step 1](/articles/article-2/step1.png)

### 2. Image Preprocessing
- **Image Resize+ Node**: Resizes the loaded image to a suitable resolution (e.g., 1024x1024 pixels), ensuring it meets the input requirements of SDXL for optimal processing and results.

![Step 2](/articles/article-2/step2.png)

### 3. Background Processing
- **RemBG Session+ Node**: Utilizes a background removal model to isolate the subject from its background effectively without any prompt given. 

- **Image Remove Background+ Node**: Further refines the removal of the background, ensuring a clean and distraction-free subject image that gives `IMAGE` and `MASK` as output.

> This node could be replaced with a more advanced model like a combination of `segment-anything` and `GroundingDINO`that can be prompted to segment a specific element from the image and provide better results. https://github.com/storyicon/comfyui_segment_anything

- **DepthAnything Preprocessor Node**: Applies a depth estimation model to the image, adding a depth map that creates a 3D effect. This can make the results more engaging by giving it a lifelike quality.

![Step 3](/articles/article-2/step3.png)

- **ControlNet Loader Node**: Loads a ControlNet model configured to apply specific conditioning adjustments to the image.
- **ControlNet Apply Node**: This node applies the loaded ControlNet conditioning to the image, adjusting aspects like style, color, and composition based on the encoded textual descriptions.

![Step 5](/articles/article-2/step5.png)

### 4. Textual Conditioning
- **CLIP Text Encode Nodes**: Two instances of this node encode textual descriptions into conditioning signals. 

- Top node handles positive prompts (e.g., "advertisement photography, a man in the park of Eiffel tower") and the botton handles negative conditioning to avoid unwanted elements (e.g., "illustration, anime, distorted"). 

- This text-based guidance helps tailor the generative model's output more closely to the desired advertisement theme and is connected with the `LoRA` node.

![Step 4](/articles/article-2/step4.png)

### 5. Image Synthesis
- **KSampler Node**: A critical node where the actual image synthesis occurs. It takes conditioned inputs and model outputs to generate new sections of the image or modify existing ones, incorporating the learned features and styles specified by the ControlNet and text encodings.

> **Note**: The `KSampler` node is the heart of the workflow. Most of the models and checkpoints you find online have instructions on how to use them with the `KSampler` node as there are specific parameters for each model to perform and give optimal results. 

![Step 6](/articles/article-2/step6.png)

### 6. Latent Space Manipulation
- **Empty Latent Image Node**: Generates a blank latent space image which can be used as a starting point for synthesis.
- **VAE Decode Node**: Transforms the latent representations back into image space, solidifying changes and ensuring that the output remains visually coherent.

![Step 7](/articles/article-2/step7.png)

### 7. Final Adjustments and Outputs
- **Image Blend by Mask Node**: Simply takes all the processed images and masks and blends them together to create the final output.

![Step 8](/articles/article-2/step8.png)
- **Preview Image Nodes**: Used throughout the workflow to visualize the processing stages and final outputs.

![Step 9](/articles/article-2/step9.png)


## Workflow Results

> #### Result 1

![Output Result 1](/articles/article-2/output11.png)


> #### Result 2

![Output Result 2](/articles/article-2/output2.png)

---

> #### Result 3

![Output Result 3](/articles/article-2/output3.png)

---

> #### Result 4

![Output Result 4](/articles/article-2/output4.png)
