---
cover: /articles/article-5/cover.png
date: 2024-07-01
description: Comparing Zero-shot Identity-Preserving Models + Bonus, Running workflows on fal.ai
layout: article
---
# ComfyUI: Pulid vs InstantID

**Building a comparison workflow for Zero-shot Identity-Preserving Models. Running workflows on [fal.ai](https://fal.ai).**

![Workflow Screenshot](/articles/article-5/cover.png)

### If you like my posts, make sure to follow me on:

- [Hugging Face](https://huggingface.co/martintmv)
- [GitHub](https://github.com/martintmv-git)

## Table of Contents

1. [Running Workflows on fal.ai](#running-workflows-on-falai)
2. [Models and Nodes Setup](#models-and-nodes-setup)
   - [Models](#models)
   - [Nodes](#nodes)
3. [Workflow Overview](#workflow-overview)
4. [Workflow Results](#workflow-results)
5. [Credits](#credits)

## Running Workflows on fal.ai

[fal.ai](https://fal.ai/dashboard/comfy) introduced ComfyUI integration in their platform, allowing developers to build and run workflows directly on their servers while receiving an API endpoint that can be later used in their own custom apps (Python and JavaScript). Input fields can be converted to `fal inputs`, which gives the ability to control the parameters from UI outside ComfyUI.

![fal inputs](/articles/article-5/fal-inputs.png)

This gives developers the ability to instantly turn their ComfyUI workflow into a scalable API.

You can choose if you want your workflow to be public or private, giving you extra flexibility. The platform also provides a detailed log of your workflow, including the input and output of each node, error logs (if any), and the time taken to run the workflow. This is a great small feature for debugging and monitoring the performance of your workflow.

Workflows can be tested in fal's playground before deploying them as API endpoints. This allows you to check if everything is working as expected before making it public. I'm excited to see how this feature will evolve in the future: maybe they will introduce a way to share workflows with other users, or even a community gallery for workflows.
![workflow on fal](/articles/article-5/fal.png)
![Workflow deployed on fal.ai](/articles/article-5/workflow.png)

## Models and Nodes Setup

Running the workflow locally on your machine requires the installation of specific models and nodes. Here is a list of the models and nodes used in this workflow:

### Models

- [dreamshaperXL_lightningDPMSDE](https://huggingface.co/gingerlollipopdx/ModelsXL/tree/main)
- [ip-adapter_pulid_sdxl_fp16](https://huggingface.co/huchenlei/ipadapter_pulid/tree/main)
- [instantid-controlnet](https://huggingface.co/InstantX/InstantID/tree/main)
- [instantid-ip-adapter.bin](https://huggingface.co/InstantX/InstantID/tree/main)

### Nodes

- **ComfyUI Manager**: A tool for managing nodes and models within ComfyUI. [ComfyUI Manager GitHub repository](https://github.com/ltdrdata/ComfyUI-Manager)

> **👉🏻 You can install all missing nodes in a workflow, or install custom nodes with ease from the Manager Menu. Restart your ComfyUI after installation.**
> ![ComfyUI Manager](/articles/article-1/comfyui-manager.png)
> Of course, you can install nodes manually with `git`, but the Manager is a great tool to have.

## Workflow Overview
Detailed Step-by-Step Workflow Explanation

---

### 1. Loading the Face Image
**Node:** `LoadImage`  
**Function:** This node loads a face image that will be used as the base input for subsequent processing steps. The image must contain a face for the workflow to work.

> ![image](/articles/article-5/input.png)
---

### 2. Loading Checkpoint Model
**Node:** `LoadCheckpoint`  
**Function:** Loads a Stable Diffusion checkpoint model that includes the base model, CLIP, and VAE components. Crucial for the image generation, initializing the models that will be used in next steps.

---

### 3. Loading the InstantID Model
**Node:** `LoadInstantIDModel`  
**Function:** Loads the InstantID model, which will be used to apply instant identification features to the image. This model assists in enhancing and identifying specific features in the image.

---

### 4. Loading the Pulid Model
**Node:** `LoadPulidModel`  
**Function:** Loads the Pulid model for to apply instant identification features to the image.

---

### 5. Loading the EvaCLIP Model
**Node:** `PulidEvaClipLoader`  
**Function:** Loads the EvaCLIP preprocessor model, required by Pulid.

---

### 6. Loading ControlNet Model
**Node:** `LoadControlNetModel`  
**Function:** Loads the ControlNet model, which is used for InstantID.

---

### 7. Empty Latent Image
**Node:** `EmptyLatentImage`  
**Function:** Generates an empty latent image with specified dimensions. This latent image serves as the starting point for image generation and manipulation.

---

### 8. Encoding Text Prompts (Positive)
**Node:** `CLIPTextEncode`  
**Function:** Encodes positive text prompts to condition the model. These prompts guide the model in generating the desired features in the image. This node was converted to a `fal input` for more flexibility in the API endpoint.

> e.g. "close up of man posing for a picture in the centre of Amsterdam near water canals, photorealistic, realism" - positive prompt

---

### 9. Encoding Text Prompts (Negative)
**Node:** `CLIPTextEncode`  
**Function:** Encodes negative text prompts to condition the model. These prompts help in avoiding undesired features during the image generation process. **This node doesn't particularly need to be converted to a fal input, as the negative prompt I chose is multi purpose.**

> e.g. "blurry, malformed, low quality, worst quality, artefacts, noise, text, watermark, glitch, deformed, ugly" - negative prompt

---

### 10. Applying Pulid Model
**Node:** `ApplyPulid`  
**Function:** Applies the Pulid model to process the image through the parameters that are set. 

> e.g. method, weight, start_at, end_at - parameters

---

### 11. Applying InstantID
**Node:** `ApplyInstantID`  
**Function:** Applies the InstantID model to process the image through the parameters that are set.

> e.g. weight, start_at, end_at - parameters

---

### 12. Sampling with Pulid Model
**Node:** `KSampler`  
**Function:** Generates result from the Pulid model using the provided conditioning and latent image. This node refines the image based on the Pulid model's capabilities.

---

### 13. Sampling with InstantID Model
**Node:** `KSampler`  
**Function:** Gengerates from the InstantID model using the provided conditioning and latent image. This step ensures the image is refined according to the InstantID model's parameters.

> Both KSampler nodes and their parameters particularly might be useful to be converted to `fal inputs` for more flexibility in the API endpoint.

---

### 14. Final Decoding with VAE
**Node:** `VAEDecode`  
**Function:** Decodes the final latent image back to a visual image using the VAE (Variational autoencoder) model.

---

### 15. Saving the Pulid Image
**Node:** `SaveImage`  
**Function:** Saves the processed image from the Pulid model.

> ![output1](/articles/article-5/output1.png)

---

### 16. Saving the InstantID Image
**Node:** `SaveImage`  
**Function:** Saves the final processed image from the InstantID model.

> ![output2](/articles/article-5/output2.png)

---

## Workflow Results

![output2](/articles/article-5/result1.png)

![output3](/articles/article-5/result2.png)

![output4](/articles/article-5/result3.png)

## Credits:
- [InstantID](https://github.com/InstantID/InstantID)
- [Pulid](https://github.com/ToTheBeginning/PuLID)
- [cubiq](https://github.com/cubiq)
- [fal.ai](https://fal.ai)

#### And of course, the ComfyUI community! 🧡